{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_raw = 'hk_clean.txt'\n",
    "df = pd.read_csv('hk_clean.txt',sep='\\n', names=['documents'],header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus(fname=path_raw):\n",
    "    with open(fname) as f:\n",
    "        lines = iter(f)\n",
    "        #lines.next()\n",
    "        for line in lines:\n",
    "            yield line\n",
    "\n",
    "class CorpusFriendly(object):\n",
    "    def __init__(self,fname, topK=None):\n",
    "        self.topK = topK\n",
    "        self.fname = fname\n",
    "\n",
    "    def __iter__(self):\n",
    "        k = 1\n",
    "        corpus_memory_friendly = get_corpus(self.fname)\n",
    "        for context in corpus_memory_friendly:\n",
    "            #data = gensim.utils.to_unicode(data).split(',')\n",
    "            seg_context = jieba.cut(context, cut_all=True)\n",
    "            words = \" \".join(seg_context).split()\n",
    "            #print \", \".join(words)\n",
    "            label = [str(k)]\n",
    "            yield gensim.models.doc2vec.TaggedDocument(words, label)\n",
    "\n",
    "            if self.topK:\n",
    "                if k >= self.topK:\n",
    "                    break\n",
    "                k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corpus_train = CorpusFriendly(fname='hk_clean.txt',topK=3)\n",
    "# for c in corpus_train:\n",
    "#     print \", \".join(c.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>课题一 列强的入侵第一章中英鸦片战争乾隆晚年清朝隔世油性转衰嘉庆道光以来政治腐败经济凋敝社会...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>从18世纪後期开始英国锐意拓展对华贸易并希望在对等的基础上和清廷交旺但清廷却自居天朝上国轻视...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第一次鸦片战争前中外贸易关系清朝的外交贸易态度清朝秉持传统的政治观念以天朝上国自居视海外诸国...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>中国是一个农业社会经济自给自足因此清廷对外贸易发展并不积极并认为准许外商来华贸易只是嘉惠远人...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>清朝对中外贸易的管理措施清初厉行海禁政策至1684年康熙帝收复台湾后才解除海禁指定广州漳州宁...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents\n",
       "0  课题一 列强的入侵第一章中英鸦片战争乾隆晚年清朝隔世油性转衰嘉庆道光以来政治腐败经济凋敝社会...\n",
       "1  从18世纪後期开始英国锐意拓展对华贸易并希望在对等的基础上和清廷交旺但清廷却自居天朝上国轻视...\n",
       "2  第一次鸦片战争前中外贸易关系清朝的外交贸易态度清朝秉持传统的政治观念以天朝上国自居视海外诸国...\n",
       "3  中国是一个农业社会经济自给自足因此清廷对外贸易发展并不积极并认为准许外商来华贸易只是嘉惠远人...\n",
       "4  清朝对中外贸易的管理措施清初厉行海禁政策至1684年康熙帝收复台湾后才解除海禁指定广州漳州宁..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for c in get_corpus('hk_clean.txt'):\n",
    "#     print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-03 18:45:49,148 : INFO : collecting all words and their counts\n",
      "2016-12-03 18:45:49,193 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2016-12-03 18:45:49,478 : INFO : collected 12907 word types and 1 unique tags from a corpus of 647 examples and 96272 words\n",
      "2016-12-03 18:45:49,505 : INFO : min_count=1 retains 12907 unique words (drops 0)\n",
      "2016-12-03 18:45:49,506 : INFO : min_count leaves 96272 word corpus (100% of original 96272)\n",
      "2016-12-03 18:45:49,536 : INFO : deleting the raw counts dictionary of 12907 items\n",
      "2016-12-03 18:45:49,536 : INFO : sample=0 downsamples 0 most-common words\n",
      "2016-12-03 18:45:49,537 : INFO : downsampling leaves estimated 96272 word corpus (100.0% of prior 96272)\n",
      "2016-12-03 18:45:49,537 : INFO : estimated required memory for 12907 words and 2000 dimensions: 215555100 bytes\n",
      "2016-12-03 18:45:49,554 : INFO : constructing a huffman tree from 12907 words\n",
      "2016-12-03 18:45:49,954 : INFO : built huffman tree with maximum node depth 17\n",
      "2016-12-03 18:45:49,959 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "corpus_train = CorpusFriendly(fname='ma_clean.txt')\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=2000, min_count=1, iter=30, window=10, workers=6)\n",
    "model.build_vocab(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-03 18:45:51,568 : INFO : training model with 6 workers on 12907 vocabulary and 2000 features, using sg=0 hs=1 sample=0 negative=0\n",
      "2016-12-03 18:45:51,568 : INFO : expecting 647 sentences, matching count from corpus used for vocabulary survey\n",
      "2016-12-03 18:45:52,665 : INFO : PROGRESS: at 2.47% examples, 89395 words/s, in_qsize 2, out_qsize 0\n",
      "2016-12-03 18:45:53,832 : INFO : PROGRESS: at 7.47% examples, 98119 words/s, in_qsize 9, out_qsize 0\n",
      "2016-12-03 18:45:54,843 : INFO : PROGRESS: at 12.47% examples, 109762 words/s, in_qsize 9, out_qsize 0\n",
      "2016-12-03 18:45:55,865 : INFO : PROGRESS: at 17.05% examples, 110918 words/s, in_qsize 12, out_qsize 0\n",
      "2016-12-03 18:45:56,928 : INFO : PROGRESS: at 22.47% examples, 115814 words/s, in_qsize 9, out_qsize 0\n",
      "2016-12-03 18:45:57,971 : INFO : PROGRESS: at 27.05% examples, 115454 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:45:59,020 : INFO : PROGRESS: at 32.43% examples, 114403 words/s, in_qsize 12, out_qsize 0\n",
      "2016-12-03 18:46:00,082 : INFO : PROGRESS: at 36.68% examples, 115006 words/s, in_qsize 8, out_qsize 0\n",
      "2016-12-03 18:46:01,162 : INFO : PROGRESS: at 40.80% examples, 113889 words/s, in_qsize 9, out_qsize 0\n",
      "2016-12-03 18:46:02,168 : INFO : PROGRESS: at 45.79% examples, 114170 words/s, in_qsize 9, out_qsize 0\n",
      "2016-12-03 18:46:03,331 : INFO : PROGRESS: at 50.02% examples, 113700 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:04,441 : INFO : PROGRESS: at 54.13% examples, 111975 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:05,448 : INFO : PROGRESS: at 58.23% examples, 110911 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:06,458 : INFO : PROGRESS: at 63.35% examples, 112585 words/s, in_qsize 8, out_qsize 0\n",
      "2016-12-03 18:46:07,520 : INFO : PROGRESS: at 67.04% examples, 111137 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:08,548 : INFO : PROGRESS: at 70.80% examples, 110556 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:09,586 : INFO : PROGRESS: at 74.29% examples, 110104 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:10,845 : INFO : PROGRESS: at 80.02% examples, 110041 words/s, in_qsize 11, out_qsize 0\n",
      "2016-12-03 18:46:11,983 : INFO : PROGRESS: at 84.29% examples, 109476 words/s, in_qsize 12, out_qsize 0\n",
      "2016-12-03 18:46:13,000 : INFO : PROGRESS: at 89.13% examples, 110224 words/s, in_qsize 9, out_qsize 0\n",
      "2016-12-03 18:46:14,074 : INFO : PROGRESS: at 93.35% examples, 109727 words/s, in_qsize 12, out_qsize 0\n",
      "2016-12-03 18:46:14,731 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2016-12-03 18:46:14,743 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2016-12-03 18:46:14,808 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2016-12-03 18:46:14,870 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2016-12-03 18:46:14,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2016-12-03 18:46:15,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2016-12-03 18:46:15,007 : INFO : training on 2888160 raw words (2612490 effective words) took 23.4s, 111475 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2612490"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-03 18:46:57,203 : INFO : saving Doc2Vec object under gensim_doc2vec_ma_clean, separately None\n",
      "2016-12-03 18:46:57,204 : INFO : not storing attribute syn0norm\n",
      "2016-12-03 18:46:57,205 : INFO : not storing attribute cum_table\n",
      "2016-12-03 18:46:57,206 : INFO : storing numpy array 'syn0' to gensim_doc2vec_ma_clean.syn0.npy\n",
      "2016-12-03 18:46:57,377 : INFO : storing numpy array 'syn1' to gensim_doc2vec_ma_clean.syn1.npy\n"
     ]
    }
   ],
   "source": [
    "model.save('gensim_doc2vec_ma_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-03 18:46:58,177 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大会 0.487304121256\n",
      "邓小平 0.426903009415\n",
      "错误 0.425654470921\n",
      "恩来 0.409264981747\n",
      "七届 0.406742185354\n",
      "中央 0.40299975872\n",
      "救亡图存 0.401721507311\n",
      "修正 0.397239804268\n",
      "召开 0.394397318363\n",
      "决定 0.389851659536\n",
      "左 0.389674842358\n",
      "领导 0.381504237652\n",
      "4 0.371776252985\n",
      "代表人 0.370344400406\n",
      "报告 0.364824742079\n",
      "举行 0.362404286861\n",
      "过渡时期 0.357644736767\n",
      "3 0.354215204716\n",
      "周恩来 0.353090584278\n",
      "思想 0.35283434391\n",
      "严复 0.352674037218\n",
      "文章 0.345772027969\n",
      "两万多 0.344606101513\n",
      "会议 0.343152761459\n",
      "互助 0.342843621969\n",
      "台下 0.342572450638\n",
      "76 0.335445225239\n",
      "出席 0.335164159536\n",
      "李大钊 0.333106100559\n",
      "他 0.332416325808\n",
      "马列 0.331359565258\n",
      "南昌 0.331095695496\n",
      "袁世凯 0.330088376999\n",
      "五个 0.326589643955\n",
      "刘伯承 0.325404465199\n",
      "想为 0.320692956448\n",
      "汪精卫 0.31683576107\n",
      "朱德 0.315772920847\n",
      "三中 0.314972966909\n",
      "制 0.313936114311\n",
      "35 0.311945468187\n",
      "二中 0.310921907425\n",
      "三个代表 0.308386087418\n",
      "正面 0.308221697807\n",
      "根据地 0.306825041771\n",
      "389 0.306708037853\n",
      "如期举行 0.305099487305\n",
      "主持 0.304352432489\n",
      "变法 0.304013311863\n",
      "10 0.303497284651\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=[u'毛泽东'], topn=50)\n",
    "for e in result:\n",
    "    print e[0], e[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "市 0.519082963467\n",
      "左右 0.508009254932\n",
      "资产 0.501721024513\n",
      "捐款 0.490958988667\n",
      "行家 0.474751919508\n",
      "争先恐后 0.468380063772\n",
      "积极开展 0.462161868811\n",
      "党员 0.450659692287\n",
      "便利 0.449199587107\n",
      "果断 0.447492331266\n",
      "世纪 0.443939208984\n",
      "广泛开展 0.443811774254\n",
      "阶级 0.438615262508\n",
      "傀儡政权 0.421137571335\n",
      "谈判 0.420939385891\n",
      "提升 0.414148569107\n",
      "适 0.411298900843\n",
      "配给 0.407960355282\n",
      "京畿 0.407841801643\n",
      "共产党人 0.407772958279\n",
      "严格 0.407211601734\n",
      "联 0.405010282993\n",
      "万股 0.403754293919\n",
      "用活 0.403723239899\n",
      "配上 0.397625029087\n",
      "毁坏 0.396900743246\n",
      "马克思主义 0.395297348499\n",
      "聚会 0.393555939198\n",
      "七次 0.39193046093\n",
      "升华 0.39175003767\n",
      "相比 0.39160245657\n",
      "收 0.390299022198\n",
      "逆差 0.388421416283\n",
      "国际金融 0.387688845396\n",
      "贸易逆差 0.385262787342\n",
      "极为 0.384791254997\n",
      "七 0.384758532047\n",
      "第一次 0.381829559803\n",
      "大力开展 0.380911022425\n",
      "割让 0.380042076111\n",
      "急切 0.379683464766\n",
      "年限 0.377444684505\n",
      "下旬 0.376877367496\n",
      "尖锐 0.375366687775\n",
      "七条 0.374831289053\n",
      "合作 0.37399405241\n",
      "无产 0.373658210039\n",
      "法规 0.369240820408\n",
      "邮政局 0.368238627911\n",
      "一三 0.367492556572\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=[u'共产'], topn=50)\n",
    "for e in result:\n",
    "    print e[0], e[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
